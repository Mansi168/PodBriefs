{
    "podcast_details": {
        "podcast_title": "Go Time: Golang, Software Engineering",
        "episode_title": "A deep dive into Go's stack",
        "episode_image": "https://cdn.changelog.com/uploads/covers/go-time-original.png?v=63725770357",
        "episode_transcript": " Welcome to Go Time, your source for diverse discussions from all around the Go community. Big thanks to our partners for helping us bring you awesome pods each and every week. Fastly.com, fly.io, and typesense.org. Okay, here we go. What's up, friends? I'm here with Jeremy Tanner, DevRel at Tailscale, and I've been using Tailscale for the past, I want to say the last year, and I consider it critical home lab infrastructure for me. As you may know, I'm a home labber, so that means I take pride in a solid home network, Wi-Fi, services that make the home run, home assistant for automation, lighting. And of course, I run Piehole to block ads at the network level and to protect my family from ad tracking. And Piehole has this web UI that you can access from the land. But for a while there, I just didn't have access to this service or other services like Portainer or Just anything else that had a web UI or something I would access via IP on the local area network. But Jeremy, tell me about a world where via tail skill you can access pie hole, portainer or any of these other services you might run in your home lab and access it externally from a local area network. Yeah, you hit it when you said anything, anything and from anywhere. And so, Piehole being a DNS black hole, if you notice the difference between the comfy experience that you had at home and when you were out of your house, whether it was for work, coffee shop, or even on your mobile devices, being able to set up a tail scale on your mobile device and have access to the same pie hole and filtering rules. that you do at home, wherever you have an internet connection is a thing. Same thing when talking about streaming, instead of exposing your network storage to the internet and getting that ransomware, keeping that on your private network, but extending the private network to any device that can run the client. Anything that can run the client includes your Steam Deck, that's just a Linux box with the controllers grafted onto the sides of it. If you're somewhere that has internet connection and wants to watch some of your video, plug it up to a large TV and if you're in a hotel room, use that as your media center that's playing the shows that you're trying to catch up on from home instead of whatever hotel TV has on it. Instead of buying a service or paying a small monthly subscription, like you have, you have computer storage at home, it's just an easy way to get back to those instead of usually inventing a bunch of things that you'd love to do but those sorts of things become accessible to you on your phone while you're outside the house instead of something that's neat to use but then you miss while you're away. Yeah, for sure. You know, I run Plex, so I'm in big agreement with that, of course. But just being able to do what you can do with Tails Scale is so cool without having to learn all the VPN things. It's just such an easy tool to use, easy tool to install on anything, really Linux, Windows, Mac. So easy to use. Big, big fan of Tailscale. And for my home lab users out there, you can totally use Tailscale 100% for free. You get three users, up to 100 devices, which is like way more devices than I think I would ever need to use Tailscale on. The Free Forever Tier is amazing and a great place to start and especially to use it for your home lab needs alone. Check them out at changelog.com slash tailscale. The Free Forever Tier is waiting for you to try it out again changelog.com slash tailscale. And make sure you tell them your friends at changelog sent you. hello and welcome to go time I'm Matt Ryer today we're talking all about the go stack what on earth is it what does it do how much do we have to care about it how much do we have to know about it as programmers in order to be effective we're gonna dig in and find out joining me today co-host of course Chris Brando hello Chris hi Matt how's it going Not bad. Has anything dramatic happened to you recently in your building? Unfortunately so. New York City has had some unfortunate accidents as of late and I was unfortunately affected. But we're all good now. We're all good. Okay, good. But you didn't cause any? No. You didn't cause it? No. Good. We're also joined today by Yarden Leifenfeld. Hello, Yarden. Yarden is a software engineer at Rookout, or as of Monday, Dynatrace, where you've been developing a production-grade debugger for Go. That's very exciting. We'll definitely talk about that. You're also one of the organizers of Go for Con Israel, as well as the Women Who Go Israel group. Welcome, Yarden. Hi, thanks for having me. Absolute pleasure. And from the Go team, we're joined by David Chase. David's been working on compilers and runtimes for around 40 years and started working on Go in Google back in 2015, which I think is eight years ago, David. Welcome to Go Time. Hi. I don't know what else to say. Yeah, no, high is fine. Absolutely fine. But are you actually something interested in your bio that you grow lilies and you're a judge for the North American Lily Society? That was like this weird thing ages ago. I mean, so when we do vacations ages ago, we had a job, we had a vacation and work, but they let me drive and my wife was alone and she would plan some days and I would plan some days and we're planning. I'm She plans very well, and I plan about five seconds ahead. Just in time planning. Yes, really. And so, yes. And so, we were driving along. We see this sign that says Lilies in Begonia's next drive. We say, oh, that's cool. We like Lilies. And we go. And the guy that we met was the, it turns out, a famous and incredibly innovative lily breeder. Oh, this is cool. He gives me his catalog, and I just order a few, and I start growing them. And it basically took, and I've just been doing it for years, and like them, and there's a local society, and they said, oh, we need help out, and I help out more, we need judges, and trained myself up to be a judge, which is like this multi-year process with exams and test judging and everything. And I need to emphasize, I am like a kind of a junior judge which on the one hand you kind of get amazed at the things that you learn and then on the other hand the guys who are really good at it just like okay wow you can get that much better it's it's it's sort of weird so like you'll be out and people someone will ask you a question about lilies and you will just start riffing and explaining and like all this and this and this. Wow, that's amazing. Are they difficult to grow, I guess? Not especially. And that's part of one of the reasons I like them because I can do a concentrated bit of work that's important. And then it's like, I would just like to leave that there and let it take care of itself. In the US, there was an introduced pest from Europe that for a while made it very difficult. They've introduced a natural control, a specific wasp with specific taste in host for its larvae. And it's naturalized here and it has made it be a fine thing to do. You just grow them and they're fine. I should stop. I could talk longer. No, no, no. I mean, maybe we should just do Lily time. Yeah, we'll do that next. Yeah. Wow. Okay, great. And, and yeah, Yarden, and actually something you both have in common, you both like bikes and cycling and stuff, right? Yarden, do you do a lot of that? I wrote it as a response to David's mentioning of bikes. Yeah, I just read it again. It says you're not good with bikes. That's true. I wouldn't say that I'm not good with them, but I'm not. We did. I'm not especially good with bikes. Like I can ride one. I do ride one. What more do you need? Exactly. Yeah. Well, fixing them, I guess, as well. Someone else does that for me. Yeah, just get David to do it. David fixes bikes as well. David, if you want lilies, if you want lilies growing or you need your bicycle fixed, David's your man. Maybe. Yeah. But so, and yeah, Yarden, before you did Go, you wrote Java, some Ruby, some C-sharp, C++, Python. What is it about Go that grabs your attention? I'm actually doing all those now. Like I wrote out, or I guess I should say Dynatrace. We're supporting all of those now. But my main focus is Go. I think before I did Go, I did C. And I really like that, like the simplicity of it and the closeness to like bare metal. I know it's not really that close to bare metal, but it's as close as people usually get nowadays. Yeah, relatively. Yeah, exactly. And so I think I liked the similarities to Go rather than all those like higher level languages. Yeah. What's your favorite language out of those then? It would be either Go or C. Definitely. Nice. Good answer. Okay, cool. So maybe we could just get started. I'd love to start at the basics. What is the stack? What actually is that? And what does it do? In Go terms, it's like a slice, but internally, it's used very much that way. It has a capacity. allocates from high addresses to lower rather than low to high, which is what you would do in a slice. And whenever you make a call to a function or a method, it extends the slice towards lower addresses by a constant amount. Per function, each function has its own constant. That's the size of its stack frame. And it uses that for scratch storage. And so your local variables, And the temporaries that might need to be spilled to memory, that's the memory that they would spill to. That's the memory for the local variables. And depending upon your calling convention on your architecture, you may pass parameters to functions and methods that you call also in stack space. Since Go 1.17, on some architectures, we use registers But we still reserve stack space for spilling them for certain purposes. The interesting difference from slices is, well, no, actually, that's not true. And so your slice has a capacity. But you can just keep on appending to a slice on and on and on and on. And if you append out past the capacity, if you're appending, it says, oh, need to make it bigger. And it allocates a new slice, if it's a slice, And in the case of the stack, Go is unlike a lot of programming languages here. It allocates a new stack, copies the old one to the new. A thing that it does that is particular to Go is all the locations of all of the pointers that might be on the stack are recorded and those are all updated. when you do the stack copy. And so your program has no idea that this is going on. You just did a function call and the stack got copied into a new place and it's bigger and all of the internal pointers to its own stack got updated in that copy and it carries on. Is that an expensive operation? It is. I mean, it's just memory copying and then scanning the stack and interpreting the pointers, but you don't do it very often. It's sort of a hysteresis. You don't The stack stays large until the garbage collector looks at a Govertine's stack and says, wow, we've allocated you a megabyte and yet you're only using 10 kilobytes. I think we'd like some of that back and then it fixes it and it puts you back into a smaller stack. And so it is an expensive operation to grow it, but it doesn't happen very often. You grow to a large enough size. An alternate implementation that they used earlier and that has been used in other programming languages from time to time is segmented stacks. And so you don't relocate the old one, you just allocate a new piece of stack to be in. And the problem with these is that you have sort of a hysteresis problem in a crossing problem. If you happen to have that boundary at a place where you're doing a lot of function calls, you always trip over it because it's not a smooth, easy increment. It's like, oops, I hit the end, got to do an extra thing. Even if you've got that other stack there, it makes that function call more expensive. What I'm saying is even if you've set it aside and say, yeah, I know I'm going to do this, so I'm going to cache my next segment and reuse it, you trip over that. And it's expensive enough that everyone that's done it, that I know of that's done it the segmented way, unless they have a really good reason to keep on doing it in that segmented way and there are other reasons, but Go doesn't have them. They move to the contiguous stack in the recopy. This is a changelog news break. Have you already asked ChatGPT how to design a good UI for your new AI app and gotten back Bubkiss? Well, check out LangUI, an open source tailwind library of 60 plus responsive and dark mode enabled components tailored for AI and GPT projects. What exactly does that mean? It means prompt containers, history panels, sidebars, message inputs, and all sorts of stuff that are chat by related. So you can stop asking chat GPT and build your own chat GPT with a sweet UI. You just heard one of our five top stories from Monday's changelog news. Subscribe to the podcast to get all of the week's top stories and pop your email address in at changelog.com slash news to also receive our free companion email with even more developer news worth your attention. Once again, that's changelog.com slash news. when the Go rector shrinks the stack, does that happen when like after like a Go routine is kind of done being used or does it like happen at like a like you pause the Go routine or like, at what point does that happen? Because you said we grow stacks when we hit like a function call. That's like a clean space to do it. So is there like a similar analogous clean space where it can shrink the stack? So certainly if you are paused, so if your Go routine is not actually running, It could be runable, but not allocated to a thread and actually running. In those cases, I believe that if it's at a clean stop, it can shrink the stack. So we have to talk about preemption here. If you need to preempt a go routine, say if you need to do a garbage collection, So the garbage collector has to do a handshake with the thread. There's two kinds, cooperative and uncooperative. And so the cooperative one is part of the entry sequence to almost every function, where it checks to see if it has overflowed the stack bound. And what it does is, if the runtime needs to interrupt, it lies about what the stack bound is. The govRoutine says, oops, I guess I need a new stack. Goes into that code and says, oh, actually, I'm here for this other reason. someone needs to interact with me. And that's a clean cooperative preemption. And the state of all the pointers is well known. And so you have the option of shrinking the stack at that point. And since that's also the place where you grow the stack, if it needs to grow, that makes sense. Couldn't grow the stack if you couldn't find the pointers either. Uncooperative preemption occurs, if you have a tight, long running loop, we don't check on back edges, we profiled whether we should explicitly check there and we could not get the cost down enough. So, we do a thing where we interrupt the go routine and there are places where we can't and it records those, it looks and says, am I at a safe enough place? So, it's not a safe point where you know everything, but it's a safe enough place and you might not know everything. But you know that it's okay to run a garbage collection at that point. And it's okay to examine the stack, but you don't know everything you need to know about the pointers in that last frame. So you can't move the stack. Sorry, this took so long, but it's like there's a reason and there's a reason and there's a reason. It's more complicated than it used to be eight years ago. It certainly doesn't sound easy. And something you mentioned, which is interesting, and Yarden, maybe you could shed some light on this. You mentioned that it grows the stack towards the lower memory address, right? What's that all about? How is it even doing that? Does it literally just have to reserve a load of memory and then it's sort of working backwards? What's the advantage of it doing that? I'll start by saying that Go Stack works a lot like a regular stack. And by that I mean like even if you write a binary in C where there's no runtime that's controlling the stack and stuff like that, you're still gonna have a section of memory called the stack that works in a very similar way with a lot of the similar things on it. And so Go really mimics that behavior and it makes sense because it's a good concept. And in a regular, I'm saying regular, but just in a non-Go or non-managed binary, the stack does go from the higher addresses to the lower addresses just because you have like this big section of memory and you've got or you've got a big stuff of memory and you've got sections in it and so the stack will be one section and the heap will be another and they'll kind of grow towards each other so the heap will go from low to high and the stack will go from high to low and they'll get closer And then, so go, I said, go does it like this. And the thing with allocations is that, and David correct me if I'm wrong, it does usually have, like it will allocate a stack when it's needed. But if I'm remembering correctly, it does usually like keep the stacks aside. Like there's a lot of reuse of like allocated stacks. I don't think it is intentionally reusing stacks, but it might. That's a part of the runtime. I don't know, actually. The garbage collector would sort of tend to do it for the smaller sized stacks just because it would say, well, that's a size class. And so anything of that size goes in a little pile of 4K or 8K or 16K chunks. And it would go there again for the next time it needed something that size. Oh, that's cool. I thought it was like specifically for stacks, but I guess that makes sense. It might be. I that that's a chunk I don't know about. It does sound like stacks and like stacks really are just kind of slices that are just in this. Oh, they're just in a special place in memory and we just use them for go routines and all that doesn't sound like they're that special of a thing. Sort of the end of the stack has some extra. Now, where did we put the G? Every Go routine has this thing called the G or the G structure. And I don't actually know if we keep it at the base of the stack or the end of the stack. What's the G stand for? Go routine, I think. Cool, isn't it? It's a good name. Well, I don't know if I was looking at the code and I saw a structure that's just called G. I mean, obviously that's a concept that exists in that domain. There's a couple of those single letter things, right? There's like G's and P's and M's. Yes. The thing is, how do you call your variable type G? Lowercase G? G. G-E-E, maybe? No, G. Just G? Just G. Yeah. But are these like primary concepts and therefore they sort of deserve this? Because it's almost like a status. It's a bit of a power play for a struct to call itself just a single letter, I think, isn't it? It's a bit of a move. Well, it's in the runtime, so there's a name base. So it's not polluting everyone else's namespace. You could have your own G, you can have your own M and your own P. It's allowed. Yeah, should you? That's the question, isn't it, David? I do think it's the basics, though. My whole approach to learning about the Go runtime has basically been looking at the code and just trying to understand what's going on there. You've done a pretty good job of maintaining readable code, but there are spaces that have been difficult, especially since I might not know the background for why it's there. And so I do try to kind of complete that with reading stuff that people who have written that code wrote. And so a lot of the stuff when you start getting into the runtime, we'll talk about P's and M's and G's and because that's really the basics of how Go even works and how it is so fast and efficient and how it enables Go routines or lightweight threads. So that's really where everything starts. Yeah. So one of the nice things, of course, about Go being open source is we can go and look at this code. We can actually go and dig in and look at this. And it's Go code. It doesn't sound like it's the easiest code base to understand, but it certainly sounds like we have a good chance. But Yarden, do you have to do a lot of that? Do you have to dig in because of the work that you're doing? And you've got to really understand. I get to do a lot of it. Oh, you love it. I do. It's so interesting just because it is really complex and things that are done there are amazing. And because I'm also writing Go code, I'm understanding what's happening in my code because I'm reading the code that runs my code or that compiles my code. There's just so many layers to understanding it that make me a better developer and also interests me, I guess. So do you recommend people do dig in and learn about this for that reason? Or could you still be a good enough Go programmer without even knowing and just let David and that lot worry about this and you? I think that kind of varies. I think that if you're just starting out with the language, then diving into its internals or how it works is not the right way to go. But I do think that if you've been writing in Go for a while, or if it's like a big part of what you do, It might make you a better developer because it might not only help you understand things and just help you avoid bugs that might just happen because of incorrect use. It may be common, but it still could be incorrect use. And then if I'm going on to the more positive side, it could also make your code better because you know how to improve performance using little things from the runtime and how the runtime works. And if you know the different sections of memory and you can control which things are where and stuff like that. So definitely for more advanced developers, I think it's important. I think having some historical knowledge or like, you know, back in the day, it was probably a little bit more useful. Like, for instance, you know, we're talking about these G's and M's and P's and the M's are threads. I don't know why they're not called T's, but, you know, whatever. But the P's are actually like like cores on your processor and until Go 1.5 by default, you only got one of those. So even though you have all these Go routines running, like you're still doing kind of single, like single thing at a time execution, not doing parallel execution. Which I think is one of those things, you know, at least in my early days of go surprised me a lot is that like, oh, I'm doing all these things thinking they're happening in parallel and they're actually happening concurrently. And I think when you start looking into the runtime stuff, you can kind of see where those differences are because that's really difficult to grow. I remember the first time I watched Rob Pike's talk about, you know, concurrency is not parallelism and being kind of like This is difficult to understand, but when you can go and look at something and see it tangibly, I think that helps quite a bit. Yeah, I totally agree. I think like also it kind of brings it down to like our developer level, I think. Like when I think of the Go developers, they're like kind of these imaginary creatures in my mind that know everything about everything and know how to create the perfect programming languages. Have you seen my Go? Oh, the Go team, you mean? Yeah. No, not like individual Go developers, just the Go team, only them. No, but seriously, I'm like, okay, these people know everything about everything, and they know how everything works. And then reading the code, it's like, oh, wait, they write code like me. I write code, and they write code, and I can read the code they write. And suddenly, community-wise, I think it's really cool to think about how they're just part of the community, and we're all in it together, kind of. Yeah, I understand that. Like, that effect definitely happens. The thing is, Yardin, don't forget you are extremely intelligent. Like that. You know what I mean? That's not all of us. Oh, sorry, man. Not me. I'm talking about Chris. About me? No, obviously. I'm just kidding. Obviously not. People in general. Yeah. Yeah. Actually, I think, was it George Carlin who said, consider the average intelligence person and then realize half people are dumber than that. which is quite brutal, but quite funny. I mean, I think that's kind of mean because your other, I mean, the other way to look at it is that you're busy. Oh, there you go. And you have a lot of things to do and stuff can slip your mind. Exactly. That's why my socks are on the wrong way. I'm just busy. Yeah, you have more important things than the orientation of your socks. Trousers. And I feel like we're all, I mean, this is a bit philosophical, but I think we're all like intelligent in different ways. And I think that's kind of like what you were getting at Yarden with, you know, seeing the Go team and we're all like from the outside, it's like, oh man, they all know everything about everything. But it's like, no, there's some people that are, you know, they know the compiler very well and they know the runtime very well and they know this part of their world and they have no idea how the other parts work and they rely on the breasts of the team to kind of fill in that information. It's kind of comforting in a way. Yes, it absolutely is. Well, David, when you joined the Go team, how long had you been writing Go before you joined the Go team? Oh, about zero days. You must have aced that interview somehow. So there is a rule and it was told to me and we're certainly allowed to repeat it, which is it certainly interviews here. How would you put it politely? Don't try to BS your way through the interview. Right. That's great advice generally, I think. And so stick to what you know. And that's, you know, that's what you're being evaluated on. You're not being evaluated on the stuff you don't know. You're being, you know, how good are you at what you do? And so I didn't know any Go, but that was OK. Did you take a lily in? Not for that, no. I have brought them in a couple of times. You have a nice one in your garden and you bring it in. It's nice. That is actually genuinely nice. But yes, so zero days. Started working in Go. It's not a hard language to learn. I had a little bit of trouble. And I'm trying to think of like, how do you explain this to a really beginning programmer? There are types that are sort of reference-ish. like slices and maps, slice of maps are really reference types. If you pass a map and it gets modified, you'll see the modifications. If you pass a slice and it gets modified, you'll see some of the modifications. You won't see it. If it grows, you'll see your own, your old copy of the data. And so to me, that's kind of a, and you won't, you won't see the extensions. You'll only see changes made to the part that you passed. Yeah, it's quite unusual. Yeah. And so that, that's always that's like the one part of the language that has always sort of given me the creeps. But then when you look at problems people have in the field that they never get that wrong, seemingly, and I do not understand. And maybe people just it's maybe that's kind of How do you put this? Like I'm always sort of a little worried about what's the pathological thing that could go wrong. And so I immediately gravitate to, ooh, they could do that and that would go wrong. People don't do that. So it's fine. Maybe it's people have gotten like hurt by that. Like the first few times they've tried and then they've just like found something that works and then they've stuck to it. I don't even recall hearing people being hurt by it. This is what's so strange. And I have a friend who is working in Go in sort of a very different way, big, you know, huge programming language background, former assistant professor in everything and worked at IBM research. And he's sort of explaining these things to him. And he's like, oh, that's just awful. But it's never been a problem. And so it's just kind of like this weird thing where no one seems to get it wrong. So yeah, I picked up the language pretty quickly, which was good because I was working on a compiler for it, so I kind of needed to know how it worked. Yeah, but to Yarden's point, this highlights something which I think is an important lesson for everybody, which is You have to get good at knowing how to learn and that's the important skill. You don't have to know all the things and have everything in your head. You have to be able to learn in a targeted way based on what it is you're doing, what problems you're solving. because that's something that a lot of junior devs, they see, like Yaden was saying, they see people giving a talk and the talk is just packed. And obviously they've just done a lot of work to research that subject and they've, or they've got direct experience. The best talks usually is someone telling stories of something real that they've done. So they've specialized in that in order to do that, which is actually a great reason to give talks, because if you really care and you want to learn about something, that's a great way to do it. but you don't have to know all the things and have all that stuff in your head. And I think that is a nice thing for everyone to remember, especially when you're new, because you don't have the experience of doing that so much. And it can look like people are just these geniuses. Yeah, like I have a lot of experience sort of mentoring, I guess, really, really, really beginners. And the biggest like issue I faced with people who like this is their first time writing code, is having them like try the thing they're thinking of because they'll kind of they'll sit at the computer and look at the screen and they'll be and like I'll come and ask like what's going on and they'll be like I'm not sure how to do this and I'll be like okay how do you think and they'll tell you the solution and maybe right and it may be wrong but I'm like okay why don't you write it down and try it. And there's no real answer, right? It's just like, oh, I didn't know I could do that. Or like, I didn't really think, like, put that, get that stuff there. And I think that's the first part to, like, advancing as a developer is just trying things out and learning that way. Definitely the, oh, I didn't know. Oh, really? I can do that. Okay. So same goes for reading Go internal code. Yeah, there are pieces of it that are a little creepy. The concurrency stuff is just where the weirdly tuned things like, I need to synchronize with that thread over there. And I think I'll spin for just a little bit. And someone figured out, yeah, yeah, that was a good thing to do. And then sometimes the spinning becomes inappropriate. If there's some weird architectural change. how Numa is your processor. What if the thing that you're spinning on never makes it into your cache for some crazy reason? And then you have a horrible problem. I feel like Go is pretty good at allowing you to still get access to all that kind of scary stuff, but also Not throwing it at you to start off with, like I think your point about slices, David, I think one of the reasons why people don't mess slices up is because they never learn about arrays until you're kind of like much further into the language, right? It's not like a thing that comes up that often when you're first learning language. It's like, here's a slice. This is what you would have in another language that is an array. Use it just like that. Whereas I think if you kind of dove in and we were like, OK, well, there's these slices things and these array things, and they're similar but different. And one can grow and the other can't. And I think that would probably lead to slices being much more confusing, but just having you be like, here's the thing. It's a list of data items. Go use it like that. I think people are like, OK, we'll use it. And you can stick new ones on the end and just keep doing that, and it's fine. Yeah. I agree that it's kind of interesting that people can intuitively understand. It's like, oh, well, if I modify something that's already in a slot, I'll see it on both sides. But if I grow the thing, then it's a new thing. But I think also the API helps a lot with that too, right? It's like, oh, if I allocate, if I append, I get a new slice back. And that's a different thing than the one I had before. The one I had before stays the same. Yeah, that's true. But that is unusual to say when you append to a slice. In other languages, I haven't really seen that, particularly I'm talking about Ruby and C sharp, I guess. Yeah, so you and I have seen occasionally I've seen somebody will append and don't they don't reassign it back to the slice. And then of course, it's just sometime, you know, it's just unusual. But it's that like you said, David, that is really quite rare that that happens. It may just be how they're explained in the beginning. Yeah, you just learn that that's how you append to things and therefore that's what you do and you're good. Yeah. So Yarden, I want to go back to something you said because you talked about how learning about these internals has made you a better programmer. How do we control what goes on the stack and what goes on the heap? Because at no point you're not saying like, oh, add to stack. There's no functions you're calling to do that. So how do we know stuff's going to go on the stack or on the heap? How do we actually control that? That's a good question. I am going to say that Go has some magic voodoo that I'm not entirely sure about. I can tell you what for sure goes on the stack, which is when you create a local variable, for instance, it's going to be on the stack. Or when you pass an argument to a function, it's probably going to be on the stack. David did mention earlier that it might be in a register, but I think when we think about it overall, it's just not going to be on the heap. So that's what we should be thinking about. And then the place where this kind of gets complicated is that what's not on the stack, which is things that are on the heap. And those are things that are usually allocated and we don't know how much memory they're going to take ahead of time. So like if we think of a regular variable like an integer or a float or anything like that, we're going to know ahead of time exactly how much memory it's going to take. And so that's going to be on the stack. But if we create a map or a slice or an array with an unknown number of slots, I guess, or items, that would probably end up on the heap. And I did say there's some magic going on, it depends like exactly how you did it, but overall that's the idea. And then when we talk about pointers, it gets a little more complicated because if we pass a pointer as an argument to a function, and this is where it gets interesting, is how does the garbage collector know when that pointer is out of use or when the data it's pointing at can be released and so overall the general idea is put as much things on the stack because the stack as David said is scratch storage it's like automatically cleaned up it does not need the garbage collector and then only if you need to use pointers and only if you need something on the heap you'll do that just to like avoid the overhead of the garbage collector running. Right. You say when it's on the stack, it's automatically cleaned up. So what happens when a function returns? Because presumably those arguments go on the stack in order to call a function. So then when that function returns, is there something that happens? So yes and no. Yes, theoretically. When we think about the stack, we like to think of some sort of pointer to the end of the stack. And then that moving once we return from a function. So everything, the way the stack is built, as we said, it's from higher addresses to lower addresses. And then the last chunk is going to be the last function that was called. And so if we look at like a stack trace at a certain point, we're going to just see that's how our memory is going to look. That's how our stack is going to look. We're going to have like the variables from the last function and then the variables from the function that called that and so on and so forth. And so we kind of like to think of the pointer to the end of the stack moving to the previous function when we return from our current function. And so that's the theoretic part, part where we actually do something. In practice, except for that pointer, we're not changing anything. So that memory isn't going anywhere. It isn't being zeroed out or something like that. But the next time that we write to that same space on the stack, it's just going to be overwritten. And we're going to just basically think of it as not existing. So the stack isn't really growing and shrinking, or not as we call functions and as we return from them. Just the pointer to the end of it is moving. Yeah, because I guess it would be just extra work to just zero out the memory or something. So there's no need for it, right? Yeah, exactly. It's like doing the minimum you can to achieve what you want. People don't want it. It would be slower and people don't like slower. There have been people in the world of crypto who have asked for things like that. If I ever wrote an important thing anywhere in memory, how quickly could I get that zeroed after I'm done with it? They kind of ask about that. And it's been proposed. We're not, we don't know what's the best way. Is there no way for them to just programmatically change it to a different value? So the problem here is that the compiler sees that they're doing a bunch of writes to something that they're not going to read or do anything with. And it says, I could make that run faster for you. Let me just get rid of those writes. Yeah. I mean, which also then tells you the right thing to do, which is you would have another piece of code that you've ran that verified that what you wrote there was really and truly zero. But that would take more time. And then the crypto guys say, well, wait, we didn't want me to take that much time. There's no pleasing them really, is there? Yeah, it's always the crystal crypto guys. There's no pleasing anybody. I mean, when it comes to security, though, talk about slow, I was listening to one of the change login friends episode where they have the oxide computer folks on and they were talking about how they had to like take the printer, they printed out the secret key on and like drill a hole through its microcontroller and all of this to make sure that all of the that you couldn't ever like recover the key or anything. So that in terms of slow is like, OK, well, that's a whole whole big process. But I think, you know, it does Kind of say something important about, you know, how we think about computing and how much we're like, speed, speed, speed. And it's like, well, maybe sometimes we should have a little bit of a like safety trade off for speed. We just have to figure out where that that balance is, but. How quickly could you smash a printer though, Chris? I reckon I could get a printer smashed quite quickly. Like destroy a printer. But it's not just any printer. It has to be the correct printer. And you have to smash it in the right way too, right? Cause you have to make sure that all of the chips and the memory and everything is just, even the drum, you want to make sure if it's like one of those printers that like there's no image. It's a lot. Put it in some hot lava. That's one way. Throw it in the lava and lower it down. That's what I learned from the Terminator. Just one of the things I learned from the Terminator franchise. Industrial Shredder. And it's a printer. They've never been good to us. No, they haven't. They're the worst thing that we have to deal with, aren't they, printers? They're amazing now compared to what they were, but they're still the worst thing in the world, aren't they? The original IoT device and the most terrible of any that we've invented. Yeah. Yeah. I hate printers. I don't want to say that too loudly in case mine hears me and then I'll have problems next time. Yeah. Yeah. It used to be like, you used to be like, Oh, you can't print because your printer's not online. So, and then she'd go and press a button to say, right online. And then it's like, Oh, hang on then. It's like, why is this even a feature? What do you mean? Why would you want it to ever be offline? I don't know. Bloody printers. So, uh, speaking of stack and heap though, Yardin, you mentioned that, you know, oh, sometimes you want to like try and make things be in the stack, try and make things in the heap. Do you have any like suggestions for people of how they might be able to control this, when they should control that, when they should care about doing either of those things or any of that? So as I said, like you should almost always put things on the stack, which means like, okay, I know, like from my experience, I said that I wrote C for a while before I started with Go. and see a really big thing is to pass pointers around. And the reason is not to copy big structures from one place to another when it's not necessary to copy them. I guess it's a thing of the past when we didn't just have really small hard drives that have a lot of space in them, where we wanted to save on memory, which isn't really such a big deal now, but that's how I was taught. And so I kind of took this practice with me to go, but it's really wrong because anywhere you can copy a struct, which means just pass it around as it is without taking its pointer, you should do that because then it can be, as I said, it can be cleaned. and you're not giving any extra work to the garbage collector, which has to say, oh, there's a pointer here, and then also just remember there's a pointer here, and then also go back and see where is that pointing to? Does that have any additional pointers? Okay. So you should not be using pointers to save on memory. That's a big thing I learned. But you should be using pointers in case you want to share a reference to something. So sticking to that will probably get you a performance boost if you haven't been doing that so far. Yeah, so that's really counterintuitive. And I think I see people even that are new to go when they learn about a pointer and passing something and it gets copied. And instinctively, I think even without that, that experience with C, instinctively, you think, well, I'll just pass pointers all the time. I see like slices to pointers of types and things like this, because it's like, oh, of course, just pointing to it, that's much easier. That's really interesting. I'm just sorry, I'm just sitting here thinking about how it relates to the calling convention. What's that? Where we do use registers, we are willing to use a whole lot of them. What's the register? What is a register, David? What is a register? That's a fixed amount of abstractly before they started doing all the crazy things that they do in modern processors. You have a very small amount of scratch storage. And it's a fixed size and they've got fixed names, zero, one, two, three, four, five, you know, yeah, up to sometimes 31 and sometimes more. And everything you do, really do, you end up doing it, moving it in and out of, out of memory into those registers, then you have all the operations on registers, and then you want to hang on to it and you store it. Sorry, I don't know what they implement them with nowadays. So abstracted now. Very much. And now with speculative execution and hyperthreading, they have a layer of indirection between the names and the actual registers. And there's still a relatively small amount of them compared to the gigabytes of memory that you might have on a machine. And so now, instead of 31 or 64, you might have a couple hundred, but it's still a small fixed number. You have a number of names for them. And the instructions have, you know, the machine instructions, which have a fixed size, have special fields where you code those small numbers, which are the names into them. And that's a register. I hope that works. You were asking about pointers or mentioning, you know, use of pointers and not. And there's a thing that Go does that Java does a little bit, other programming languages tend not to do it as much. They do this thing called escape analysis, so that Just because you make a point, there were reasons sometimes to make a pointer to something. Sometimes you need to call a function somebody else wrote and it says, I'm sorry, I take a pointer or, you know, maybe I wish to, you know, I wish to share that thing. I wish to do some changes to it. And then you need to see them. And then rather than taking a whole structure and passing it back, I decided for whatever reason to operate on a pointer. Go has this property on its package imports that there aren't any cycles. And what that means is that if you look at the runtime package first, it doesn't depend upon anything else. So you can compile it and you can be done. And you can know things about the functions in the runtime package. And then you go up a little more and you have another layer of packages that depend upon runtime and nothing else. And so for each function, you can say, well, I passed a pointer to it. But when that function was done, it did not save a copy of that pointer anywhere else. It didn't store it into the heap or anywhere else. So it's done. And you could leave the thing that it pointed to on the stack. That would be OK. And what they call this is escaping. So the pointer did not escape. It didn't get stored into the heap or communicated to another thread. And they have this phase called escape analysis. And for functions and methods, they do escape summaries so that you can call a function and in kind of a crude way know that it did or didn't reveal it to the rest of the world, didn't store it in the heap. And so this is a way that you can keep a little bit more stuff on the stack than you would ordinarily. And does that happen at compile time? Or is that a runtime thing? That happens right now. That happens at compile time. We have been talking about how to do more of it. and do a better job? And we have among ourselves, we have these competing proposals and we go back and it's kind of a which of these is going to yield the most improvement? Are they going to have associated like a runtime tax to have this little gadget sitting around helping? And you know, sort of what's the risk in the implementation? How hard will it be to get this done and not have screwy bugs prop up. And so, there's an idea that you might tell a function that returns something that it allocates. Since it returns memory that it allocated, it says, well, I can't put that in my stack because my stack, when I return, my stack will be gone. So, I guess it has to be on the heap. And there's this question of could we change the calling convention to functions that return pointers to say, here's a place you could use this memory here. because the caller might see the lifetime of the result and say, yeah, I get this thing back. I use it and I'm done and I don't do anything more. Is there a way to hand it to him? And in Java, there have been implementations of Java. There was actual hardware with features for this by a company called Azul, where you would allocate initially and it would try and keep it on the stack and say, oops, sorry. And the hardware would have sort of a high speed fault and it would record that one was a bad idea to do on the stack. Don't do that again. And so, but since it was in a hardware, the overhead was low. It was not like some software gadget. So in the future, it would know, take the other path. But meanwhile, this thing that you were just about to overwrite that you need to escape. put it somewhere else to fix it. But in the future, don't do this. So it had like little clever hardware gadgets to help. And the question is how much could you do? How far could you go in software? Would it be worth it? The Go garbage collector is not when you compare it to others like the Java garbage collector. It's a little slower to allocate and it's a little slower to collect garbage. What you get back is that it doesn't move memory. it handles interior pointers and it has an extremely small stop the world pause time. So have this kind of like these interesting trade-offs and it doesn't have a lot of overhead to use pointers. But what that means is that, so the trade-offs for what you might want to do to avoid a heap allocation, you might be able to spend a little more and have it still be profitable. Yeah, I've definitely done some things in code in the past to make sure that what I'm writing doesn't escape to the heap. Just be like, no, I'm going to write this in a specific way to make sure that the escape analysis makes it, okay, this will definitely go on the On the stack and one of the things that I want I think we talked about it maybe in our tooling episode or episode on tools. We love is like a way to run like analysis in the same way you can do code coverage that will then your editor turn things like green or red like I would like it to turn all of my variables like I don't know blue or some color to be like these all escape to the heap and these will all be on the stack. So I think that would be also really helpful as a way to visualize for things that the compiler or analysis tools are very sure will not escape or are pretty sure will escape. And that would be, I think, a really helpful thing in this area as well, because I think we kind of lack tooling, and it's a lot of intuition and then analyzing your code after the fact to see, did that actually wind up on the heap? I don't know. So if there's a way to see it more tangibly, I think that'd be super useful. So there are two answers, at least two answers to that. And one of them is that we've had these discussions with people at Go users in other companies. Some of them are very focused on performance and also with people working on the IDE. And so there's a flag you can pass to the compiler. It's kind of a little screwy. It's not one that a human would be happy to do, but it's intended for an automated workflow. You could say, here's this flag, dash JSON equals zero comma a directory name. And it will, for all the packages compiled, drop JSON in there in an encoded, I think it's a URL encoded, I think, name of the package. And it will talk about anything that basically the compiler logs all of its failures there. You know, mea culpa, mea culpa. Sorry, couldn't get the bounds check out. Sorry, had to heap allocate this. Sorry, you know. And it's in LSP format, the stuff that VS code uses. And it was a little screwy to encode compiler messages. This is like the information you'd get from dash m equals one or m equals two. but in JSON, LSP, format JSON. And so you could, in principle, pull this into an IDE. But one problem with this is that, I mean, stuff goes wrong all the time. And from the point of view of the compiler is failing you constantly. The bounce checks are still in here. Sorry, the null check is still here. Sorry. But most of the time it doesn't matter because most of your time is spent in just a few places. And so you need to combine that, I think, with something like profiling so that you focus your attention on where the problem is and not all the other places. Because otherwise you would just say, oh, look at this. A compiler is so terrible. Look at all it didn't do for me. And we're sort of working on that. There's PGO coming. Where are we at now? think it's experimental that we're doing more soon. So that's why you mentioned that it's not really for a human because it's too noisy. I don't think it's really for a human because it's too noisy. I think that there's another filtering step that you would need either to look at their profile and say, I need to look at this function Please show me the bad news for this function. Do you have a capture on it that says I am a robot? They have to click. That's one way. No, we do not. I think that would be actually like that's the thing I was going to say too is like it'd be nice if this was integrated into go please or language servers in general so you could kind of surface that information. So I do think it's I think i would definitely use it in the way that i also use like coverage testing and be like i care that this function in particular or this file or this package is like very optimized so i'm going to go look at you know all nice coverage stuff i think it'd be nice to be able to do that for like those specific places but i think you're right too you don't want people just kind of looking at some random function that gets called once and being like, let me make sure it doesn't put anything on the heap. It's okay. A bit like reflection where people are like, you know, I've built a lot of those like startup utilities that do like flag analysis and all of that. People are like, you're using reflection here. I'm like, it gets called once when your process is starting. It is fine. Like, don't worry. It's okay if it's slow. We don't need to hyper optimize this. Well, that raises a really good point, which we do mention this a lot, which is measure first and optimize after. But this raises a good question since the Go team are busy beavering away under the hood, changing things and adding optimizations and doing a lot of great work there. Is it possible that we optimize our code and then a new version of Go comes out, which makes some changes that then makes our code less performant or makes some of our optimizations unnecessary? Is that possible to happen? Should we keep re-measuring and reassessing? I would never say never. You just said it twice, David. I did. I did. I would say never say never more than twice. Four times. Carry on. Okay. No, go on. Sorry. It's been annoying. Right. Right. So, I mean, I think that one thing that we would aim to do is to make some of your hard work in the past now be unnecessary. I have a bee in my bonnet to look into could we reorder fields and quit telling people that they should sort their fields to make their structures more compact. And we could make the optimization guide that much shorter. And then all of your good work sorting those fields out. Sorry, that was time wasted. Also, if anyone actually cares about the order of their fields. Like binary encoding or something, it often matters. Yeah, stuff like that, good. But, you know, and by the way, this is not likely to happen anytime soon, but it's just kind of a, you know, if we did that, we could do that. And then, you know, one step would be shorter. But ordinarily, no, we don't, people don't like it when their code gets slower. I can see, so you may recall when Spectre and Meltdown came out, the security. So for security things, sometimes the security fix is just going to make your code I can't remember where I saw it, but it was something horrifying with Java strings and two ways of encoding Java strings and passing them to something. And you could have a race. And so it essentially, it validates the data and then it uses the data. And because it validates and then uses it, you could have a thread racing to screw the data up in ways that it was no longer valid. Oh, if you got in there in between those two operations. Yeah, yeah, yeah. And so you can get very strange behavior. And I'm sure they're going to fix it. And the way they're going to fix this thing is they're going to have to put in a copy. So you're going to copy it. Then you're going to validate it. And then you're going to use the version that no one can mess with. And so you added some expense. And Spectre and Meltdown, it's like, you thought your processors were cool and fast. And we're going to slow them down. a little bit. And we're going to make you generate code a little differently if that's your problem. It's like, too bad. It's slower now. And when you first hear about Spectre and Meltdown and I guess Rowhammer, it's just kind of like, you did that? Oh, crap. Because you'd like to think that the hardware is just going to work and not do these bad things to you. Yeah, I think to kind of go back to that point we were talking about with like struct field reordering, one of the things I thought about, so yeah, it's nice when you order things so they're nice and compact and fit in a small amount of space, but because of how caches work, sometimes you want the opposite of that where you're like, no, no, no, I want these things to be on different cache lines. If you put them on the same cache line, my performance will just go out the window completely. So you can see how difficult of a problem this would be to kind of automatically solve for people. But that is not Go 101. And I also don't think that we would be solving that automatically. Well, yes. But I mean, that's also not a thing that you would inflict on a beginning Go programmer. Yeah. I mean, I was saying if you reordered the fields of a struct, you might reorder them in a way that puts things in cache lines that shouldn't be next to each other or something like that. Well, you also have to have a way to be specific. Anytime you talk to another programming language or the OS, things should be just so. And if they're not too bad for you. Right. Yeah, speaking of that, we've reached the point in the show where it is time for our Unpopular Opinions! Okay, Yardin, do you have an unpopular opinion for us? I do. I think it's really unpopular. My opinion is that Go should not add any new big features to the language. Why not? Well, I like simple. I like simplicity. You asked me earlier what my favorite language is. I said C and Go. And I think the reason for that is because when I look at Go code or when I look at C code, I know what's going on there. And when I look at Java code, if someone has different conventions, like coding conventions, or if someone is using a newer feature that I'm not familiar with, the code might be virtually unreadable to me. And I think Go did a great job. of really keeping it simple. I love that it really forces you into a certain structure. And it's not like, I don't know, we compare it to Python, where Python basically lets you do anything you want. And Go, even like Go's linters will be like, that's not how you're supposed to name a variable in Go. And I really like that. And I think it really helps get into the language. It really helps read other people's code. It really helps write good code, because if you only need to learn the basics, and then you build off of that instead of just learning more and more and more and more and more, then you're becoming a better developer so much quicker. And so all that to say that if we add any new big features, we're just getting away from that notion. And I think most big features would just go against that and not add too much value to language users. And I'm not on the code team. I don't know. Yeah. This isn't backed by statistics. You're talking David out of a job. But let me just ask you this. What about generics? How did you feel about that? Well, I think you can guess how I felt about generics, Matt. I really like it when there is one way to do things. And I know we've grown past that, I guess, as developers. And I wish we'd go back to it. No, I'm kidding. But I do like that we're advancing and that things are more abstract. But I also like that Go keeps you kind of close to it. You do need to know what a pointer is. If you heard this podcast, you know what a stack is. Important stuff like that. So, oh my God, I completely lost my train of thought. Well, that's fine. Okay. So, but David, you're not thinking of adding any big features, are you? What do you think of this? I was curious how the generics were received. There's talk about extending iterators to be more general. And there's some question about whether that wants co-routines or not. And co-routines would not be go routines, because when you code up co-routines with go routines, they're not fast enough. I do feel like that's a feature I want is co-routines. So The thing is, these are all features I want. Like I want, I wanted to generics before they existed. I was like, oh my God, I need generics. I don't have the privilege of using them just because we have to support like really old versions. But like I'm torn, but this is still my unpopular. I stand behind it. Cool. Okay, David. I have several. I don't think they're as good as no new features. As unpopular. No, not no new features. By the way, I think the standard library could use some new features. And I think like adding Macs and stuff isn't bad. Yarden, this isn't a performance review for David. No, I'm sorry. I wanted to say this, but I wanted to be like, I'm so sorry. I'm so, so sorry. Please continue working on Go. You're doing a great job. I mean, I'm not sure. I mean, one of my unpopular opinions is more, I think, unpopular with the Go team. And it's kind of like squirrely and technical. But years ago, I had a lot to do with Fortran. My advisor, they referred to him as Dr. Fortran. Sounds like an evil villain. I interned for John Bacchus. That's cool. And so I have a real soft spot for Fortran. And the thing that makes Fortran fast, it's like one tiny little thing. And it's usually true in programs. And that has to do with when you would say pass a pair of slices to a function. Fortran says, you can pretend they overlap. If they overlap, it's not Fortran. And it's this interesting rule that you can't check with syntax. But if your code overlaps, passes overlapping memory and parameters to a function, and it can tell, then it's not Fortran. So that's a convenient way of dealing with all the bug reports. They say, my code can tell that you did this And it says, well, that's fine, but that's not a Fortran bug. That's a bug in some other language you're imagined. Go away. But what this does is it lets you do vectorization just willy nilly, all sorts of vectorization transformations and parallelization transformations and reordering. And this is sort of like the key to why Fortran is so fast. And so part of me says, There's like these shaggy dog stories of, you know, all and it gets back to stacks actually, like the pain of inter-language calls and translating data between this language and that language. And it's never fun and it's always annoying. And so if you just said we could make it go fast in Go. you would need, if you did this, and it would need a lot of compiler work, and it would be more employment for people like me, which is great. But you could do this little Fortran change to the parameter rules, and then you could make code go faster. And, you know, to take this out of the previous century or the previous millennium, I'd say machine learning. Woo! Woo! Oh, so that's my unpopular opinion and it's probably more unpopular with the rest of the go team. Yeah, they probably understand it. Yes. I'm afraid that's the problem. That's the other problem is to have an unpopular opinion that people don't understand. Quite clever in a way. Another one you wrote down, David, which I quite liked was Go needs larger integer types, int 128, int 256, int 512. What are you doing with all these massive ints, David? The processors nowadays have all of these crazy extra instructions that take giant inputs and giant operands. And they encode this in C by you. For whatever reason, they chose stupid names for their integer types in C. And so when they had to go to these big integer types, they had to pick even stupider names. And you use them. And you have to include a special include file. And you pollute your code with these terrible, terrible names. And Go could have these instructions as intrinsics. and Go would have a perfectly good name for the input types in 128 and 256 and 512. And so that's, I think that would be fine. And we can implement this. We already handle 64-bit integers on 32-bit machines. people ask us things like, well, we really want to get at the intrinsics. We want to do that, and we just go around and around on the best way, and we don't have good types, so we'd have to do this hacky thing with structs, but that struct is special. It's like, oh, just say it. Ant 128. There, it's done. That reminds me of I think it's Rob Pike who might have put up a proposal to change and you went to arbitrary precision. I was like, I like that. I want some arbitrary precision directly in my language, but it could work. I think it would be interesting to look into whether you had a default behavior or a way to ask to compile code so that if they overflowed, there was a counterproposal was that if you overflow your signed integers, boom, that's a panic. It's a little bit of a security issue, but it might not be a big one for Go because the other language, I mean, there have been exploits that involved integer overflow. But they also made use of, haha, those guys don't check their array bounds. So they thought they checked their array bounds, but we overflow their integer, we get to have fun. And Go would just say, yeah, no, we checked your array bounds, get out of here. So that might not be necessary. But that was a counter proposal. I think, you know, they would not go on the stack. I mean, maybe sometimes they would go on the stack, but then they'd have to have an option to not go on the stack. True. Yeah. Well, on that bombshell, and thank you David for bringing us back to Stacks then and tying a neat bow on this. Yes, thank you so much. Yarden, thank you so much for all the community work that you do. Gophacon Israel, anyone in that part of the world wants to go and meet gophers, you know, get on board. And also the Women Who Go Israel group, like, you know something great about the go community and it's people like you putting all this work in and it doesn't we if you don't do it you don't really know how much work it is so you know i've glimpsed the amount of work that people put into this so you know thank you so much for that um david chase obviously all your work on the go team you know what can we say but thank you so much for all that stuff it's great to have you here Chris I've got nothing to thank you for apart from showing up and being yourself and thank you to our listeners for listening because honestly without you this would be genuinely pointless I was Matt Ryer thank you to me as well I'll say it no one else was gonna step up thank you very much we'll see you next time on go time Okay, I'll say it. Thank you, Matt, for showing up and being yourself. Go time wouldn't be the same without you. Better maybe, but not the same. And to you, dear listener, we would love for you to subscribe now if you haven't already. And please do check out ChangeLog news. It's the software world's best weekly news brief plus newsletter. It might be the software world's only weekly news brief plus newsletter, but it's the best too. Check it out at changelog.com slash news and wherever you get your podcasts. Thank you once again to our partners, Fastly.com, Fly.io, and Typesense.org. And to Brake Master Cylinder for hooking us up with the best beats in all the biz. That's it, I'm done, but we'll talk to you again next time on Go Time. you"
    },
    "podcast_summary": "In this episode of the Go Time podcast, the hosts discuss the use of Tailscale to access services such as Pi-hole or Portainer from outside the local area network. They also talk about the benefits of Tailscale for home lab users and emphasize the simplicity and ease of use of the tool. The hosts also touch on various topics related to Go, including stack and heap memory, learning Go internals, and the future development of the language.",
    "podcast_guest": {
        "name": "Jeremy Tanner",
        "job": "DevRel at Tailscale",
        "wiki_title": "",
        "wiki_summary": "",
        "wiki_url": "",
        "wiki_img": "",
        "google_URL": "https://www.linkedin.com/in/jeremytanner"
    },
    "podcast_highlights": "- Highlight 1 of the podcast:\n\"In practice, except for that pointer, we're not changing anything. So that memory isn't going anywhere. It isn't being zeroed out or something like that.\"\n- Highlight 2 of the podcast:\n\"...as much things on the stack because the stack as David said is scratch storage, it's like automatically cleaned up.\"\n- Highlight 3 of the podcast:\n\"...don't have a lot of overhead to use pointers.\"\n- Highlight 4 of the podcast:\n\"Yes and no. Yes, theoretically. In theory, when we think about the stack, we like to think of some sort of pointer to the end of the stack moving to the previous function when we return from our current function. And then, the next time that we write to that same space on the stack, it's just going to be overwritten.\"\n- Highlight 5 of the podcast:\n\"I think most big features would just go against simplicity and not add too much value to language users.\""
}